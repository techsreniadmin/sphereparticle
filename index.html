<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Auto Motion Particle Sphere</title>
  <style>
    body { margin: 0; overflow: hidden; background: #ccc; }
    canvas { display: block; }
    #enableMotion {
      position: absolute;
      top: 20px;
      left: 20px;
      z-index: 1;
      padding: 10px 20px;
      font-size: 16px;
      display: none;
    }
  </style>
</head>
<body>
  <button id="enableMotion">Enable Motion</button>

  <audio id="background-music" loop>
    <source src="Tobu - Live Your Life [NCS Release].mp3" type="audio/mpeg">
    Your browser does not support the audio element.
  </audio>


  <script src="https://cdn.jsdelivr.net/npm/three@0.128.0/build/three.min.js"></script>
  <script>
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
    camera.position.z = 5;

    const renderer = new THREE.WebGLRenderer({ antialias: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    const geometry = new THREE.BufferGeometry();
    const vertices = [];
    const radius = 1.5;

    for (let i = 0; i < 1500; i++) {
      const theta = 2 * Math.PI * Math.random();
      const phi = Math.acos(2 * Math.random() - 1);
      const x = radius * Math.sin(phi) * Math.cos(theta);
      const y = radius * Math.sin(phi) * Math.sin(theta);
      const z = radius * Math.cos(phi);
      vertices.push(x, y, z);
    }

    geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));
    const material = new THREE.PointsMaterial({ color: 0xffffff, size: 0.03 });
    const pointCloud = new THREE.Points(geometry, material);
    scene.add(pointCloud);

    let isMobile = /Android|iPhone|iPad|iPod/i.test(navigator.userAgent);
    let gyroX = 0, gyroY = 0;
    let gyroEnabled = false;
    let mouseX = 0, mouseY = 0;

    const enableButton = document.getElementById("enableMotion");

    if (isMobile) {
      // Check if permission request is required (iOS 13+)
      if (typeof DeviceOrientationEvent.requestPermission === 'function') {
        enableButton.style.display = "block";
        enableButton.addEventListener("click", async () => {
          try {
            const permission = await DeviceOrientationEvent.requestPermission();
            if (permission === "granted") {
              startGyro();
              enableButton.style.display = "none";
            }
          } catch (e) {
            alert("Motion permission denied.");
          }
        });
      } else {
        // Android / other mobile browsers â€“ no permission needed
        startGyro();
        enableButton.style.display = "none";
      }
    } else {
      // Desktop: mouse movement
      enableButton.style.display = "none";
      document.addEventListener('mousemove', (event) => {
        mouseX = (event.clientX / window.innerWidth) * 2 - 1;
        mouseY = -(event.clientY / window.innerHeight) * 2 + 1;
      });
    }

    function startGyro() {
      window.addEventListener("deviceorientation", (event) => {
        gyroX = event.beta || 0;
        gyroY = event.gamma || 0;
        gyroEnabled = true;
      });
    }

    function animate() {
      requestAnimationFrame(animate);
      if (gyroEnabled) {
        pointCloud.rotation.x = gyroX * 0.01;
        pointCloud.rotation.y = gyroY * 0.01;
      } else {
        pointCloud.rotation.y = -mouseX * 0.5;
        pointCloud.rotation.x = -mouseY * 0.3;
      }
      renderer.render(scene, camera);
    }

    animate();

    window.addEventListener('resize', () => {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });

    const audio = document.getElementById('background-music');
  const audioContext = new (window.AudioContext || window.webkitAudioContext)();
  const analyser = audioContext.createAnalyser();
  const source = audioContext.createMediaElementSource(audio);
  source.connect(analyser);
  analyser.connect(audioContext.destination);
  analyser.fftSize = 256;
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  function animate() {
    requestAnimationFrame(animate);
    analyser.getByteFrequencyData(dataArray);
    const averageFrequency = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;
    const scale = 1 + averageFrequency / 256;
    pointCloud.scale.set(scale, scale, scale);
    renderer.render(scene, camera);
  }

  audio.play().then(() => {
    audioContext.resume().then(() => {
      animate();
    });
  }).catch(error => {
    console.error('Audio playback failed:', error);
  });

  </script>
</body>
</html>
